const express = require('express');
const WebSocket = require('ws');
const ffmpeg = require('fluent-ffmpeg');
const fs = require('fs');
const path = require('path');

// Configuration des binaires statiques FFmpeg
const ffmpegPath = require('ffmpeg-static');
const ffprobePath = require('ffprobe-static').path;

console.log('üì¶ Using bundled FFmpeg binaries:');
console.log('   ffmpeg:', ffmpegPath);
console.log('   ffprobe:', ffprobePath);

class WebRTCVideoStreamer {
    constructor() {
        this.app = express();
        this.server = null;
        this.wss = null;
        this.currentVideo = null;
        this.currentPosition = 0;
        this.isPlaying = false;
        this.ffmpegProcess = null;
        this.streamingInterval = null;
        this.clients = new Set();
        this.lastCommand = null;  // Pour stocker la derni√®re commande
        this.playStartTime = null; // Temps de d√©marrage de la lecture
        this.playStartPosition = 0; // Position au d√©marrage de la lecture
        this.videoDuration = 0; // Dur√©e totale de la vid√©o
        this.staticFrameProcess = null; // Processus FFmpeg pour frames statiques
        this.lastPlayTime = 0; // Timestamp du dernier /play pour ignorer les /seek rapides
        this.lastStateChange = Date.now(); // Timestamp de derni√®re modification d'√©tat
        this.prewarmedProcess = null; // Processus FFmpeg pre-warmed pour latence ultra-basse
        this.shouldBroadcastFrames = false; // Contr√¥le si on diffuse les frames (pour pause sans tuer FFmpeg)
        
        this.setupServer();
        this.setupWebSocket();
        
        // Server ready message - immediate
        console.log('‚úÖ WebRTC Server is ready to accept commands');
    }
    
    setupServer() {
        // Enhanced CORS headers for QML compatibility
        this.app.use((req, res, next) => {
            res.header('Access-Control-Allow-Origin', '*');
            res.header('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');
            res.header('Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept, Authorization');
            res.header('Access-Control-Allow-Credentials', 'false');
            res.header('Cache-Control', 'no-cache, no-store, must-revalidate');
            res.header('Pragma', 'no-cache');
            res.header('Expires', '0');
            
            if (req.method === 'OPTIONS') {
                res.sendStatus(200);
            } else {
                next();
            }
        });
        
        this.app.use(express.static('../public'));
        this.app.use(express.json()); // Pour parser le JSON des requ√™tes POST        
        
        // Video control endpoints
        this.app.get('/play/:timing?', (req, res) => {
            // Marquer le timestamp du /play pour ignorer les /seek rapides
            this.lastPlayTime = Date.now();
            
            const timing = req.params.timing ? parseFloat(req.params.timing) : null;
            
            // Si un timing est sp√©cifi√©, juste l'utiliser pour le tracking
            if (timing !== null && !isNaN(timing)) {
                this.currentPosition = timing;
                console.log(`ENDPOINT: /play/${timing}s`);
                // Stocker la commande avec le timing pour Tauri
                this.lastCommand = { action: "play", time: timing };
            } else {
                console.log(`ENDPOINT: /play`);
                // Stocker la commande sans timing pour Tauri
                this.lastCommand = { action: "play", time: null };
            }
            
            this.play();
            res.status(200).json({ok: true});
        });
        
        this.app.get('/pause', (req, res) => {
            console.log('ENDPOINT: /pause (SPACEBAR)');
            
            // Stocker la commande pour que Tauri puisse la r√©cup√©rer
            this.lastCommand = { action: "pause", time: null };
            
            this.pause();
            res.status(200).json({ok: true});
        });
        
        
        this.app.get('/seek/:time', (req, res) => {
            const time = parseFloat(req.params.time);
            
            // V√©rifier si un /play a eu lieu dans les 200ms pr√©c√©dentes
            const timeSinceLastPlay = Date.now() - this.lastPlayTime;
            if (timeSinceLastPlay < 200) {
                console.log(`SEEK IGNORED: ${time.toFixed(3)}s (${timeSinceLastPlay}ms after /play)`);
                res.status(200).json({ok: true, ignored: true});
                return;
            }
            
            // Stocker la commande pour que Tauri puisse la r√©cup√©rer
            this.lastCommand = { action: "seek", time: time };
            
            this.seek(time);
            res.status(200).json({ok: true});
        });
        
        this.app.get('/set-video', (req, res) => {
            const videoPath = req.query.path;
            this.handleSetVideoRequest(videoPath, res);
        });
        
        this.app.get('/command', (req, res) => {
            // Retourne et efface la derni√®re commande (comme l'ancien serveur HTML5)
            const command = this.lastCommand;
            this.lastCommand = null;
            // Pas de log pour √©viter la redondance avec les autres endpoints
            res.status(200).json(command || {});
        });
        
        this.app.get('/video-path', (req, res) => {
            res.status(200).json({path: this.currentVideo ? '/webrtc-stream' : null});
        });
        
        this.app.get('/status', (req, res) => {
            res.status(200).json({
                playing: this.isPlaying,
                position: this.currentPosition,
                video: this.currentVideo,
                duration: this.videoDuration
            });
        });
        
        
        
        this.app.get('/clear-video', (req, res) => {
            console.log('ENDPOINT: /clear-video');
            this.clearVideo();
            res.status(200).json({ok: true});
        });
        
        this.app.get('/open-player', (req, res) => {
            console.log('ENDPOINT: /open-player');
            // Signal √† Tauri de maintenir la fen√™tre ouverte
            const client = require('http');
            const postData = JSON.stringify({
                cmd: 'keep_window_open'
            });
            
            const options = {
                hostname: 'localhost',
                port: 1420, // Port par d√©faut de Tauri
                path: '/',
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Content-Length': Buffer.byteLength(postData)
                }
            };
            
            const req2 = client.request(options, (res2) => {
                console.log('‚úÖ Tauri window keep-alive signal sent');
            });
            
            req2.on('error', (e) => {
                console.log('‚ö†Ô∏è Could not signal Tauri:', e.message);
            });
            
            req2.write(postData);
            req2.end();
            
            res.status(200).json({ok: true, message: 'Player window keep-alive signal sent'});
        });
        
        // State endpoint for HTTP polling mode
        this.app.get('/state', (req, res) => {
            res.status(200).json({
                video: this.currentVideo,
                position: this.currentPosition,
                playing: this.isPlaying,
                duration: this.videoDuration,
                lastStateChange: this.lastStateChange,
                hasVideo: this.currentVideo !== null
            });
        });
        
        // Simple ready check for QML (text response)
        this.app.get('/ready', (req, res) => {
            res.status(200).send('OK');
        });
        
    }
    
    setupWebSocket() {
        this.server = this.app.listen(5173, () => {
            console.log('WebRTC Video Server running on http://localhost:5173');
        });
        
        this.wss = new WebSocket.Server({ server: this.server });
        
        this.wss.on('connection', (ws) => {
            console.log('Ready: no video');
            this.clients.add(ws);
            
            // Send current state to new client
            ws.send(JSON.stringify({
                type: 'state',
                video: this.currentVideo,
                position: this.currentPosition,
                playing: this.isPlaying
            }));
            
            ws.on('close', () => {
                console.log('Client disconnected');
                this.clients.delete(ws);
            });
            
            ws.on('error', (error) => {
                console.log('WebSocket error:', error);
                this.clients.delete(ws);
            });
        });
    }
    
    broadcast(message) {
        const data = JSON.stringify(message);
        this.clients.forEach(client => {
            if (client.readyState === WebSocket.OPEN) {
                client.send(data);
            }
        });
    }
    
    setVideo(videoPath) {
        console.log(`DEBUG: setVideo called with path: "${videoPath}"`);
        
        try {
            this.clearVideo();
            this.currentVideo = videoPath;
            this.currentPosition = 0;
            this.isPlaying = false;
            this.lastStateChange = Date.now();
            
            console.log(`DEBUG: Video properties set, getting duration...`);
            
            // Obtenir la dur√©e de la vid√©o avec FFprobe
            this.getVideoDuration().then(duration => {
                console.log(`DEBUG: Got video duration: ${duration}s`);
                this.videoDuration = duration;
                this.broadcast({
                    type: 'video_set',
                    path: videoPath,
                    duration: duration
                });
            }).catch(error => {
                console.log(`ERROR: Failed to get video duration: ${error.message}`);
            });
            
            console.log(`DEBUG: Generating static frame...`);
            // G√©n√©rer et afficher la premi√®re frame imm√©diatement
            this.generateStaticFrame();
            
            console.log(`DEBUG: Pre-starting FFmpeg for instant play...`);
            // Pr√©-d√©marrer FFmpeg en arri√®re-plan pour latence ultra-basse au premier play
            this.shouldBroadcastFrames = false; // Ne pas diffuser, juste pr√©parer
            this.startStreaming(false); // Ne pas forcer la diffusion
            
            console.log(`DEBUG: setVideo completed successfully`);
        } catch (error) {
            console.log(`ERROR: Exception in setVideo: ${error.message}`);
            throw error;
        }
    }
    
    play() {
        if (!this.currentVideo) {
            console.log('ERROR: No video loaded');
            return;
        }
        
        this.isPlaying = true;
        this.playStartTime = Date.now();
        this.playStartPosition = this.currentPosition;
        this.lastStateChange = Date.now();
        
        // Broadcast IMMEDIATELY 
        this.broadcast({
            type: 'play',
            position: this.currentPosition
        });
        
        // Si FFmpeg est d√©j√† en cours, reprendre la diffusion imm√©diatement
        if (this.ffmpegProcess && !this.ffmpegProcess.killed) {
            console.log('PLAY: Resuming frame broadcasting (FFmpeg already running)');
            this.shouldBroadcastFrames = true;
        } else {
            console.log('PLAY: Starting new FFmpeg process');
            this.shouldBroadcastFrames = true;
            this.startStreaming();
        }
    }
    
    pause() {
        // Calculer la position actuelle bas√©e sur le temps √©coul√©
        if (this.playStartTime) {
            const elapsedSeconds = (Date.now() - this.playStartTime) / 1000;
            this.currentPosition = this.playStartPosition + elapsedSeconds;
        }
        
        this.isPlaying = false;
        this.playStartTime = null;
        this.lastStateChange = Date.now();
        
        // IMPORTANT: Arr√™ter la diffusion des frames SANS tuer FFmpeg
        this.shouldBroadcastFrames = false;
        
        this.broadcast({
            type: 'pause',
            position: this.currentPosition
        });
        
        console.log('PAUSE: FFmpeg kept alive, frames broadcasting stopped');
        
        // On garde FFmpeg en vie, on arr√™te juste la diffusion
        // La derni√®re frame reste affich√©e c√¥t√© client
    }
    
    
    seek(time) {
        console.log(`SEEK to ${time.toFixed(3)}s - isPlaying: ${this.isPlaying}`);

        // SEEK ne change JAMAIS l'√©tat isPlaying - seulement la position
        this.currentPosition = time;
        this.lastStateChange = Date.now();
        
        // Pour seek, on doit toujours red√©marrer FFmpeg √† la nouvelle position
        this.stopStreaming();
        
        if (this.isPlaying) {
            // R√©initialiser le tracking pour la nouvelle position  
            this.playStartTime = Date.now();
            this.playStartPosition = time;
            
            // Red√©marrer imm√©diatement √† la nouvelle position
            this.startStreaming();
            console.log('SEEK: FFmpeg restarted at new position (playing)');
        } else {
            // En pause : g√©n√©rer une frame statique √† la nouvelle position
            this.generateStaticFrame();
            console.log('SEEK: Static frame generated at new position (paused)');
        }
        
        this.broadcast({
            type: 'seek',
            position: time,
            playing: this.isPlaying
        });
    }
    
    startStreaming(forceBroadcast = true) {
        if (!this.currentVideo || !fs.existsSync(this.currentVideo)) {
            console.log('Video file not found for streaming');
            return;
        }
        
        this.stopStreaming(); // Ensure clean state
        
        
        const { spawn } = require('child_process');
        
        const ffmpegArgs = [
            '-ss', this.currentPosition.toFixed(3), // Seek before input for faster start (3 digits precision)
            '-re', // Read at native frame rate to avoid too fast playback
            '-i', this.currentVideo,
            '-f', 'image2pipe',
            '-vcodec', 'mjpeg',
            '-q:v', '8', // Good quality vs speed balance
            '-s', '640x360',
            '-an', // No audio needed
            '-fflags', '+fastseek+genpts+discardcorrupt', // Ultra-fast seeking
            '-avoid_negative_ts', 'make_zero',
            '-threads', '2', // Use multiple threads
            '-preset', 'ultrafast', // Fastest encoding
            '-tune', 'fastdecode', // Optimize for fast decoding
            'pipe:1'
        ];
        
        
        try {
            this.ffmpegProcess = spawn(ffmpegPath, ffmpegArgs);
            
            // Contr√¥ler la diffusion selon le param√®tre
            if (forceBroadcast) {
                this.shouldBroadcastFrames = true;
            }
            // Sinon on garde la valeur actuelle de shouldBroadcastFrames
            
            let frameBuffer = Buffer.alloc(0);
            const frameStart = Buffer.from([0xFF, 0xD8]); // JPEG start
            const frameEnd = Buffer.from([0xFF, 0xD9]);   // JPEG end
            
            this.ffmpegProcess.stdout.on('data', (chunk) => {
                frameBuffer = Buffer.concat([frameBuffer, chunk]);
                
                let startIndex = 0;
                let endIndex;
                
                while ((endIndex = frameBuffer.indexOf(frameEnd, startIndex)) !== -1) {
                    const frameData = frameBuffer.slice(startIndex, endIndex + 2);
                    
                    // Ne diffuser les frames que si on est en mode play
                    if (this.shouldBroadcastFrames) {
                        this.broadcast({
                            type: 'frame',
                            data: frameData.toString('base64'),
                            timestamp: Date.now()
                        });
                        
                    }
                    // Sinon on consomme les frames sans les diffuser (garde FFmpeg en vie)
                    
                    startIndex = endIndex + 2;
                }
                
                frameBuffer = frameBuffer.slice(startIndex);
            });
            
            this.ffmpegProcess.stderr.on('data', (data) => {
                // Logging moins verbeux
                const output = data.toString();
                if (output.includes('error') || output.includes('Error')) {
                    console.log('FFmpeg stderr:', output);
                }
            });
            
            this.ffmpegProcess.on('close', (code) => {
            });
            
        } catch (err) {
            console.log('Error starting FFmpeg process:', err.message);
        }
    }
    
    
    handleSetVideoRequest(videoPath, res) {
        console.log(`DEBUG: handleSetVideoRequest called with path: "${videoPath}"`);
        
        // Check if video is already loaded and is the same file
        if (this.currentVideo === videoPath) {
            console.log(`ENDPOINT: /set-video ‚Üí "${videoPath}" (already loaded, ignoring)`);
            res.status(200).json({ok: true, status: 'already_loaded'});
            return;
        }
        
        // Check if file exists
        if (!require('fs').existsSync(videoPath)) {
            console.log(`ERROR: Video file not found: "${videoPath}"`);
            res.status(404).json({ok: false, error: 'File not found'});
            return;
        }
        
        // Load video only if different or no video loaded
        console.log(`ENDPOINT: /set-video ‚Üí "${videoPath}" (loading new video)`);
        
        try {
            this.setVideo(videoPath);
            res.status(200).json({ok: true, status: 'loaded'});
        } catch (error) {
            console.log(`ERROR: Failed to set video: ${error.message}`);
            res.status(500).json({ok: false, error: error.message});
        }
    }
    
    
    stopStreaming() {
        if (this.ffmpegProcess) {
            try {
                if (typeof this.ffmpegProcess.kill === 'function') {
                    this.ffmpegProcess.kill('SIGTERM');
                }
            } catch (err) {
                // Ignorer les erreurs de kill
            }
            this.ffmpegProcess = null;
        }
        
        // Nettoyer aussi le processus de frame statique s'il existe
        if (this.staticFrameProcess) {
            try {
                this.staticFrameProcess.kill('SIGTERM');
            } catch (err) {
                // Ignorer les erreurs
            }
            this.staticFrameProcess = null;
        }
    }
    
    // Nouvelle fonction: g√©n√©rer une frame statique √† une position donn√©e
    async generateStaticFrame() {
        if (!this.currentVideo || !fs.existsSync(this.currentVideo)) {
            console.log('Cannot generate static frame: video file not found');
            return;
        }
        
        // Tuer l'ancien processus de g√©n√©ration de frame s'il existe
        if (this.staticFrameProcess) {
            try {
                this.staticFrameProcess.kill('SIGTERM');
            } catch (err) {
                // Ignorer les erreurs de kill
            }
            this.staticFrameProcess = null;
        }
        
        
        const { spawn } = require('child_process');
        
        const ffmpegArgs = [
            '-ss', this.currentPosition.toFixed(3),
            '-i', this.currentVideo,
            '-vframes', '1', // Une seule frame
            '-f', 'image2pipe',
            '-vcodec', 'mjpeg',
            '-q:v', '8',
            '-s', '640x360',
            'pipe:1'
        ];
        
        try {
            this.staticFrameProcess = spawn(ffmpegPath, ffmpegArgs);
            
            let frameBuffer = Buffer.alloc(0);
            
            this.staticFrameProcess.stdout.on('data', (chunk) => {
                frameBuffer = Buffer.concat([frameBuffer, chunk]);
            });
            
            this.staticFrameProcess.on('close', (code) => {
                if (code === 0 && frameBuffer.length > 0) {
                    // Diffuser la frame statique
                    this.broadcast({
                        type: 'frame', // Utiliser le m√™me type que les frames normales
                        data: frameBuffer.toString('base64'),
                        position: this.currentPosition,
                        timestamp: Date.now()
                    });
                }
                this.staticFrameProcess = null;
            });
            
            this.staticFrameProcess.stderr.on('data', (data) => {
                // Ignorer les messages d'erreur FFmpeg pour les frames statiques
            });
            
        } catch (err) {
            console.log('Error generating static frame:', err.message);
            this.staticFrameProcess = null;
        }
    }
    
    // Obtenir la dur√©e de la vid√©o avec FFprobe
    async getVideoDuration() {
        if (!this.currentVideo || !fs.existsSync(this.currentVideo)) {
            return 0;
        }
        
        return new Promise((resolve) => {
            const { spawn } = require('child_process');
            
            const ffprobe = spawn(ffprobePath, [
                '-v', 'quiet',
                '-show_entries', 'format=duration',
                '-of', 'csv=p=0',
                this.currentVideo
            ]);
            
            let output = '';
            
            ffprobe.stdout.on('data', (data) => {
                output += data.toString();
            });
            
            ffprobe.on('close', (code) => {
                if (code === 0 && output.trim()) {
                    const duration = parseFloat(output.trim());
                    console.log(`Video duration: ${duration.toFixed(2)}s`);
                    resolve(duration);
                } else {
                    console.log('Could not get video duration');
                    resolve(0);
                }
            });
            
            ffprobe.on('error', (err) => {
                console.log('FFprobe error:', err.message);
                resolve(0);
            });
        });
    }
    
    clearVideo() {
        this.stopStreaming();
        this.currentVideo = null;
        this.currentPosition = 0;
        this.isPlaying = false;
        this.playStartTime = null;
        this.playStartPosition = 0;
        this.videoDuration = 0;
        this.shouldBroadcastFrames = false;
        
        // Nettoyer le processus de frame statique
        if (this.staticFrameProcess) {
            try {
                this.staticFrameProcess.kill('SIGTERM');
            } catch (err) {
                // Ignorer les erreurs
            }
            this.staticFrameProcess = null;
        }
        
        this.broadcast({
            type: 'clear'
        });
        
        console.log('Video cleared');
    }
    
    // M√©thode pour ex√©cuter les commandes
    executeCommand(action, time) {
        switch (action) {
            case 'play':
                this.play();
                break;
            case 'pause':
                this.pause();
                break;
            case 'seek':
                if (time !== undefined) {
                    this.seek(time);
                }
                break;
        }
    }
    
}

// Start WebRTC server
const streamer = new WebRTCVideoStreamer();

// Cleanup on exit
process.on('SIGINT', () => {
    console.log('Shutting down WebRTC server...');
    streamer.clearVideo();
    process.exit(0);
});